{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd33a06",
   "metadata": {},
   "source": [
    "# Managing the environment\n",
    "\n",
    "Docker Containers: mssql, mongodb, jupyter, minio, gamestream\n",
    "\n",
    "To check if all the containers are running (docker commands in command line): \n",
    "\n",
    "PS > docker-compose ps\n",
    "\n",
    "To STOP all the containers are running (docker commands in command line): \n",
    "\n",
    "PS > docker-compose down OR PS > docker-compose stop\n",
    "\n",
    "# Starting and stopping the environment\n",
    "\n",
    "To start the environment, run the following commands:\n",
    "\n",
    "* Start the databases: PS> docker-compose up -d mssql mongodb minio\n",
    "\n",
    "* Make sure the databases are running: PS> docker-compose ps\n",
    "\n",
    "* Start the tools: PS> docker-compose up -d drill jupyter\n",
    "\n",
    "* Finally, start the gamestream: PS> docker-compose up -d gamestream\n",
    "\n",
    "* Make sure the gamestream is running by looking at the logs: PS> docker-compose logs gamestream\n",
    "\n",
    "Valid gamesteam output looks like this:\n",
    "  \n",
    "  | Added `s3` successfully.\n",
    "  | Bucket created successfully `s3/gamestreams`.\n",
    "  | Bucket created successfully `s3/boxscores`. \n",
    "  | Commands completed successfully.\n",
    "  | Commands completed successfully.\n",
    "  | INFO:root:Waiting for services...\n",
    "  | INFO:root:Bucket exists...ok\n",
    "  | INFO:root:Starting Game Data Stream. Delay: 1 second == 0.25 seconds.\n",
    "  | INFO:root:Wrote gamestream.txt to bucket gamestreams at 59:51\n",
    "\n",
    "* To stop the environment, run the following command: PS> docker-compose down\n",
    "\n",
    "* To start over from the very beginning (erase the volumes) run the following command: PS> docker-compose down -v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd742b5",
   "metadata": {},
   "source": [
    "# Managing the gamestream\n",
    "\n",
    "The gamestream container simulates the live game. Each time the game stream is started:\n",
    "\n",
    "* The players and teams database tables are reset back to their original state.\n",
    "* The live game is replayed from the beginning, writing events to s3/gamestreams/gamestream.txt as they occur.\n",
    "* The same game is played each time, with the same game events. The expected behavior will help you write the code.\n",
    "* Restarting the game steam will NOT erase any other data in mongo or other tables in mssql. See \"Start over from the very beginning\" if you need to do that.\n",
    "  \n",
    "To Restart the game stream:, run the following command:\n",
    "\n",
    "PS> docker-compose restart gamestream\n",
    "\n",
    "To view the gamestream activity, run the following command:\n",
    "\n",
    "PS> docker-compose logs gamestream\n",
    "\n",
    "Adjusting the gamestream speed\n",
    "\n",
    "By default the game stream \"plays\" at 4x speed. That 0.25 seconds of real time is 1 second of game time. You can adjust this by setting the DELAY environment variable in the .env file. DELAY=1 plays the game in real time, and DELAY=0.1 plays the game at 10x speed. If you adust the DELAY environment variable, you will need to rebuild the gamestream container. To do this, run the following commands:\n",
    "\n",
    "PS> docker-compose stop gamestream\n",
    "\n",
    "PS> docker-compose rm -force gamestream\n",
    "\n",
    "PS> docker-compose up -d gamestream\n",
    "\n",
    "NOTE: You can always docker-compose down everything and bring it back up with docker-compose up -d too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be591fc5",
   "metadata": {},
   "source": [
    "Importing Libraries and Creating a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3254652-59ff-490d-9e2d-00d9d77e2baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "com.microsoft.azure#spark-mssql-connector_2.12 added as a dependency\n",
      "com.microsoft.sqlserver#mssql-jdbc added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4b734a02-5590-4c0c-8ed6-0d5096e9a5df;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.1.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.271 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound com.microsoft.azure#spark-mssql-connector_2.12;1.2.0 in central\n",
      "\tfound com.microsoft.sqlserver#mssql-jdbc;12.2.0.jre11 in central\n",
      ":: resolution report :: resolve 588ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.271 from central in [default]\n",
      "\tcom.microsoft.azure#spark-mssql-connector_2.12;1.2.0 from central in [default]\n",
      "\tcom.microsoft.sqlserver#mssql-jdbc;12.2.0.jre11 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.1.2 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   8   |   0   |   0   |   0   ||   8   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4b734a02-5590-4c0c-8ed6-0d5096e9a5df\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 8 already retrieved (0kB/12ms)\n",
      "24/03/09 01:01:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "user = \"mongo\"\n",
    "passwd = \"SU2orange!\"\n",
    "s3_bucket = \"gamestreams\"\n",
    "s3_server = \"http://minio:9000\"\n",
    "s3_access_key = \"minio\"\n",
    "s3_secret_key = \"SU2orange!\"\n",
    "mongo_uri = f\"mongodb://{user}:{passwd}@mongo:27017/admin?authSource=admin\"\n",
    "server_name = \"jdbc:sqlserver://mssql\"\n",
    "database_name = \"sidearmdb\"\n",
    "mssql_user = \"sa\"\n",
    "mssql_pw = \"SU2orange!\"\n",
    "mssql_url = server_name + \";\" + \"databaseName=\" + database_name + \";encrypt=true;trustServerCertificate=true;\"\n",
    "\n",
    "jars = [\n",
    "    \"org.apache.hadoop:hadoop-aws:3.1.2\",\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    \"com.microsoft.azure:spark-mssql-connector_2.12:1.2.0\",\n",
    "    \"com.microsoft.sqlserver:mssql-jdbc:12.2.0.jre11\"\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "        .config(\"spark.jars.packages\",\",\".join(jars) )\\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", s3_server ) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "        .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # Keeps the noise down!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ee62a",
   "metadata": {},
   "source": [
    "# Players and Teams Reference Data\n",
    "\n",
    "The player and team reference data is stored in a Microsoft SQL Server database. The database is called sidearmdb . The database has two tables, players and teams with the following schemas, respectively:\n",
    "\n",
    "CREATE TABLE teams (\n",
    "\n",
    "    id int primary key NOT NULL,\n",
    "\n",
    "    name VARCHAR(50) NOT NULL, \n",
    "    \n",
    "    conference VARCHAR(50) NOT NULL,\n",
    "    \n",
    "    wins INT NOT NULL,\n",
    "    \n",
    "    losses INT NOT NULL,\n",
    "    \n",
    ")\n",
    "\n",
    "CREATE TABLE players (\n",
    "\n",
    "    id int  primary key NOT NULL,\n",
    "\n",
    "    name VARCHAR(50) NOT NULL,\n",
    "    \n",
    "    number varchar(3) NOT NULL,\n",
    "\n",
    "    shots INT NOT NULL,\n",
    "    \n",
    "    goals INT NOT NULL,\n",
    "    \n",
    "    teamid INT foreign key references teams(id) NOT NULL,\n",
    "    \n",
    ")\n",
    "\n",
    "* The teams table, only has two teams, 101 = syracuse and 205 = johns hopkins. Each team has a conference affiliation, and a current win / loss record.\n",
    "\n",
    "* The players table has 10 players for each team. Each player has a name, jersey number, shots taken, goals scored, along with their team id.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb226c",
   "metadata": {},
   "source": [
    "Reading Players Data from MSSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d93a740-0b7c-410f-a8ed-2ad5734c34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+-----+------+\n",
      "| id|  name|number|shots|goals|teamid|\n",
      "+---+------+------+-----+-----+------+\n",
      "|  1|   sam|     6|   56|   23|   101|\n",
      "|  2| sarah|     1|   85|   34|   101|\n",
      "|  3| steve|     2|   60|   20|   101|\n",
      "|  4| stone|    13|   33|   10|   101|\n",
      "|  5|  sean|    17|   26|    9|   101|\n",
      "|  6|   sly|     8|   78|   15|   101|\n",
      "|  7|   sol|     9|   52|   20|   101|\n",
      "|  8| shree|     4|   20|    4|   101|\n",
      "|  9|shelly|    15|   10|    2|   101|\n",
      "| 10| swede|    10|   90|   50|   101|\n",
      "| 11| jimmy|     1|  100|   50|   205|\n",
      "| 12| julie|     9|   10|    0|   205|\n",
      "| 13| james|     2|   45|   15|   205|\n",
      "| 14|  jane|    15|   82|   46|   205|\n",
      "| 15| jimmy|    16|   42|   30|   205|\n",
      "| 16| julie|     8|   67|   32|   205|\n",
      "| 17| james|    17|   40|   14|   205|\n",
      "| 18|  jane|     3|   91|   40|   205|\n",
      "| 19| jimmy|     5|   78|   22|   205|\n",
      "| 20| julie|    22|   83|   19|   205|\n",
      "+---+------+------+-----+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# READ FROM MSSQL\n",
    "players_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "players_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c5650",
   "metadata": {},
   "source": [
    "Reading Teams Data from MSSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e28cbb0-d697-478e-9159-51434732ac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------+----+------+\n",
      "| id|         name|conference|wins|losses|\n",
      "+---+-------------+----------+----+------+\n",
      "|101|     syracuse|       acc|  11|     2|\n",
      "|205|johns hopkins|     big10|   9|     4|\n",
      "+---+-------------+----------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"teams\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "teams_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bb340d-d6db-419e-9eb2-55f53f079cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|            value|\n",
      "+-----------------+\n",
      "|  0 59:51 101 2 0|\n",
      "|  1 57:06 101 6 0|\n",
      "|  2 56:13 205 8 1|\n",
      "|  3 55:25 101 4 0|\n",
      "|  4 55:03 101 1 1|\n",
      "| 5 54:50 101 17 0|\n",
      "|  6 54:14 205 8 0|\n",
      "|  7 53:59 101 9 0|\n",
      "|  8 53:23 101 2 0|\n",
      "| 9 51:21 101 13 0|\n",
      "| 10 49:55 101 1 1|\n",
      "| 11 49:28 101 2 1|\n",
      "|12 48:52 101 10 1|\n",
      "| 13 47:52 101 4 1|\n",
      "| 14 47:44 101 9 0|\n",
      "| 15 46:38 101 2 0|\n",
      "| 16 45:49 101 1 1|\n",
      "| 17 45:31 101 4 0|\n",
      "| 18 43:29 205 1 1|\n",
      "| 19 41:54 205 1 1|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the gamestream.txt from minio\n",
    "df1 = spark.read.text(\"s3a://gamestreams/gamestream.txt\")\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd637a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|            value|\n",
      "+-----------------+\n",
      "|  0 59:51 101 2 0|\n",
      "|  1 57:06 101 6 0|\n",
      "|  2 56:13 205 8 1|\n",
      "|  3 55:25 101 4 0|\n",
      "|  4 55:03 101 1 1|\n",
      "| 5 54:50 101 17 0|\n",
      "|  6 54:14 205 8 0|\n",
      "|  7 53:59 101 9 0|\n",
      "|  8 53:23 101 2 0|\n",
      "| 9 51:21 101 13 0|\n",
      "| 10 49:55 101 1 1|\n",
      "| 11 49:28 101 2 1|\n",
      "|12 48:52 101 10 1|\n",
      "| 13 47:52 101 4 1|\n",
      "| 14 47:44 101 9 0|\n",
      "| 15 46:38 101 2 0|\n",
      "| 16 45:49 101 1 1|\n",
      "| 17 45:31 101 4 0|\n",
      "| 18 43:29 205 1 1|\n",
      "| 19 41:54 205 1 1|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Write the gamestream to mongodb\n",
    "df1.write.format(\"mongo\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"database\",\"sidearmdb\") \\\n",
    "    .option(\"collection\",\"boxscores\") \\\n",
    "    .save()\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac0c61",
   "metadata": {},
   "source": [
    "# Game Stream\n",
    "\n",
    "While the game is going on, there is a file called gamestream.txt located in the minio/gamestreams S3 bucket. Each time an in-game event happens, the event is appended to this file. To simplify things, the game stream only reports shots on goal. Here is the format of the file each line is an event and the fields are separated by a space:\n",
    "\n",
    "0 59:51 101 2 0\n",
    "\n",
    "1 57:06 101 6 0\n",
    "\n",
    "2 56:13 205 8 1\n",
    "\n",
    "3 55:25 101 4 0\n",
    "\n",
    "Data Dictionary for gamestream.txt\n",
    "\n",
    "* The first column is the event ID. These are sequential. An event ID of -1 means the game is over.\n",
    "* The second column is the timestamp of the event in the format mm:ss. This counts down to 00:00. For example the first event occurred 9 seconds into the game.\n",
    "* The third column is the team ID, indicating team took the shot on goal. In the simulation there are only two teams, 101 and 205.\n",
    "* The fourth colum is the jersey number of the player who took the shot.\n",
    "* The final column is a 1 if the shot was a goal, 0 if it was a miss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06a5c1",
   "metadata": {},
   "source": [
    "Label each of the columns in the gamestream with their appropriate columns names from the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35cf344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+-------------+-----+\n",
      "|event_id|timestamp|team_id|jersey_number|shots|\n",
      "+--------+---------+-------+-------------+-----+\n",
      "|       0|    59:51|    101|            2|    0|\n",
      "|       1|    57:06|    101|            6|    0|\n",
      "|       2|    56:13|    205|            8|    1|\n",
      "|       3|    55:25|    101|            4|    0|\n",
      "|       4|    55:03|    101|            1|    1|\n",
      "|       5|    54:50|    101|           17|    0|\n",
      "|       6|    54:14|    205|            8|    0|\n",
      "|       7|    53:59|    101|            9|    0|\n",
      "|       8|    53:23|    101|            2|    0|\n",
      "|       9|    51:21|    101|           13|    0|\n",
      "|      10|    49:55|    101|            1|    1|\n",
      "|      11|    49:28|    101|            2|    1|\n",
      "|      12|    48:52|    101|           10|    1|\n",
      "|      13|    47:52|    101|            4|    1|\n",
      "|      14|    47:44|    101|            9|    0|\n",
      "|      15|    46:38|    101|            2|    0|\n",
      "|      16|    45:49|    101|            1|    1|\n",
      "|      17|    45:31|    101|            4|    0|\n",
      "|      18|    43:29|    205|            1|    1|\n",
      "|      19|    41:54|    205|            1|    1|\n",
      "+--------+---------+-------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "gamestream_df = spark.read.csv(\"s3a://gamestreams/gamestream.txt\",\n",
    "      sep =' ',\n",
    "      inferSchema = True,\n",
    "      header=False\n",
    ")\n",
    "\n",
    "headers = [\"event_id\",\"timestamp\",\"team_id\",\"jersey_number\",\"shots\"]\n",
    "\n",
    "gamestream_df  = gamestream_df .toDF(*headers)\n",
    "\n",
    "gamestream_df.createOrReplaceTempView(\"gamestream\")\n",
    "\n",
    "gamestream_df .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195fe6e",
   "metadata": {},
   "source": [
    "Group the gamestream by team/player jersey number adding up the shots and goals. \n",
    "\n",
    "1. One row per team / jersey number in the gamestream.\n",
    "2. Values dependent on team and player: total shots and goals for each player.\n",
    "3. Value dependent on only team: total goals (this should repeat for every row with the same team id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5d68ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==================================================>    (182 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+-----+---------+\n",
      "|team_id|jersey_number|shots|goals|teamgoals|\n",
      "+-------+-------------+-----+-----+---------+\n",
      "|    101|            1|    8|    6|       14|\n",
      "|    101|            2|    7|    2|       14|\n",
      "|    101|            4|    5|    1|       14|\n",
      "|    101|            6|    4|    2|       14|\n",
      "|    101|            8|    4|    0|       14|\n",
      "|    101|            9|    5|    0|       14|\n",
      "|    101|           10|    3|    1|       14|\n",
      "|    101|           13|    7|    1|       14|\n",
      "|    101|           15|    3|    1|       14|\n",
      "|    101|           17|    2|    0|       14|\n",
      "|    205|            1|    3|    3|        9|\n",
      "|    205|            2|    3|    1|        9|\n",
      "|    205|            3|    1|    0|        9|\n",
      "|    205|            5|    2|    1|        9|\n",
      "|    205|            8|    2|    1|        9|\n",
      "|    205|            9|    4|    0|        9|\n",
      "|    205|           15|    2|    2|        9|\n",
      "|    205|           16|    1|    0|        9|\n",
      "|    205|           17|    3|    1|        9|\n",
      "|    205|           22|    1|    0|        9|\n",
      "+-------+-------------+-----+-----+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "query = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        team_id,\n",
    "        jersey_number,\n",
    "        COUNT(*) AS shots,\n",
    "        SUM(shots) AS goals,\n",
    "        teamgoals\n",
    "    FROM \n",
    "        (SELECT \n",
    "            team_id, \n",
    "            jersey_number, \n",
    "            shots, \n",
    "            SUM(shots) OVER (PARTITION BY team_id) as teamgoals\n",
    "         FROM \n",
    "            gamestream\n",
    "         WHERE team_id > 0\n",
    "        ) \n",
    "    GROUP BY \n",
    "        team_id, \n",
    "        jersey_number, \n",
    "        teamgoals\n",
    "    ORDER BY \n",
    "        team_id, \n",
    "        jersey_number\n",
    "\"\"\")\n",
    "\n",
    "query.createOrReplaceTempView(\"gamestream_result\")\n",
    "\n",
    "query.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c1bdc",
   "metadata": {},
   "source": [
    "Using gamestream output to include the most most current event id and timestamp for that point in time in the game, include the latest event_id and timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7636d7-910a-4aac-b665-60024f3dca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==================================================>   (188 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+-------------+-----+-----+----------+\n",
      "|event_id|timestamp|team_id|jersey_number|shots|goals|team_goals|\n",
      "+--------+---------+-------+-------------+-----+-----+----------+\n",
      "|      70|    00:00|      0|            0|    1|    0|         0|\n",
      "|      70|    00:00|    101|            1|    8|    6|        14|\n",
      "|      70|    00:00|    101|            2|    7|    2|        14|\n",
      "|      70|    00:00|    101|            4|    5|    1|        14|\n",
      "|      70|    00:00|    101|            6|    4|    2|        14|\n",
      "|      70|    00:00|    101|            8|    4|    0|        14|\n",
      "|      70|    00:00|    101|            9|    5|    0|        14|\n",
      "|      70|    00:00|    101|           10|    3|    1|        14|\n",
      "|      70|    00:00|    101|           13|    7|    1|        14|\n",
      "|      70|    00:00|    101|           15|    3|    1|        14|\n",
      "|      70|    00:00|    101|           17|    2|    0|        14|\n",
      "|      70|    00:00|    205|            1|    3|    3|         9|\n",
      "|      70|    00:00|    205|            2|    3|    1|         9|\n",
      "|      70|    00:00|    205|            3|    1|    0|         9|\n",
      "|      70|    00:00|    205|            5|    2|    1|         9|\n",
      "|      70|    00:00|    205|            8|    2|    1|         9|\n",
      "|      70|    00:00|    205|            9|    4|    0|         9|\n",
      "|      70|    00:00|    205|           15|    2|    2|         9|\n",
      "|      70|    00:00|    205|           16|    1|    0|         9|\n",
      "|      70|    00:00|    205|           17|    3|    1|         9|\n",
      "+--------+---------+-------+-------------+-----+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Creating Temp View for players and teams table\n",
    "players_df.createOrReplaceTempView(\"players\")\n",
    "teams_df.createOrReplaceTempView(\"teams\")\n",
    "\n",
    "query1 = '''\n",
    "with cte1 as(\n",
    " select team_id, \n",
    "        jersey_number, \n",
    "        count(shots) as shots, \n",
    "        sum(shots) as goals\n",
    " from \n",
    "        gamestream\n",
    " group by\n",
    "        team_id, jersey_number),\n",
    "cte2 as(\n",
    " select team_id, sum(shots) as team_goals\n",
    " from gamestream\n",
    " group by team_id),\n",
    "latest_event_details as(\n",
    " select event_id, `timestamp`\n",
    " from gamestream\n",
    " order by event_id DESC Limit 1)\n",
    " \n",
    "select e.event_id,e.`timestamp`, c1.team_id, c1.jersey_number, c1.shots, c1.goals,\n",
    "c2.team_goals\n",
    " from latest_event_details e,\n",
    " cte1 c1\n",
    " join cte2 c2 on c1.team_id=c2.team_id\n",
    " order by c1.team_id, c1.jersey_number\n",
    "'''\n",
    "\n",
    "spark.sql(query1).createOrReplaceTempView(\"score_at_any_point_ingame\")\n",
    "spark.sql(\"select * from score_at_any_point_ingame\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec315b",
   "metadata": {},
   "source": [
    "Join the Score_at_any_point_ingame output with the player and team reference data mssql so that you have the data necessary for the box score\n",
    "\n",
    "1. players teams\n",
    "2. score_at_any_point_ingame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5076a91-de52-48f4-aa7f-d63b7058ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "|event_id|timestamp|team_id|jersey_number|shots|goals|team_goals|player_name|    team_name|conference|wins|losses|\n",
      "+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "|      70|    00:00|    101|            9|    5|    0|        14|        sol|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|           10|    3|    1|        14|      swede|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|            2|    7|    2|        14|      steve|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|            8|    4|    0|        14|        sly|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|           13|    7|    1|        14|      stone|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|            6|    4|    2|        14|        sam|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|           15|    3|    1|        14|     shelly|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|            1|    8|    6|        14|      sarah|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|            4|    5|    1|        14|      shree|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    101|           17|    2|    0|        14|       sean|     syracuse|       acc|  11|     2|\n",
      "|      70|    00:00|    205|            9|    4|    0|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|            2|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|           16|    1|    0|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|            3|    1|    0|         9|       jane|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|           15|    2|    2|         9|       jane|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|            5|    2|    1|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|            1|    3|    3|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|           22|    1|    0|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|           17|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|\n",
      "|      70|    00:00|    205|            8|    2|    1|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result = spark.sql(\"\"\"\n",
    "SELECT s.*, p.name as player_name, t.name as team_name, t.conference, t.wins, t.losses\n",
    "FROM  score_at_any_point_ingame s\n",
    "LEFT JOIN players p ON s.team_id = p.teamid AND s.jersey_number = p.number\n",
    "LEFT JOIN teams t ON s.team_id = t.id\n",
    "\"\"\")\n",
    "\n",
    "final_result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114035be",
   "metadata": {},
   "source": [
    "# The game stream's real-time box score\n",
    "\n",
    "Each time you run your code while the game is ongoing, you should write a new boxscore document to the mongodb/sidearm/boxscores collection. That way web developers can read the latest document's contents to render a webpage for live box score stats while the game is going on.\n",
    "\n",
    "For simplicity, assume team 101 is the home team and team 205 is the away team.\n",
    "\n",
    "The document should have the following structure (consider this an example)\n",
    "\n",
    "{\n",
    "    \"_id\" : \"UseTheEventIDFrom gamestream.txt\",\n",
    "    \"timestamp\" : \"55:25\",\n",
    "    \"home\": {\n",
    "        \"teamid\" : 105,\n",
    "        \"conference\" : \"ACC\",\n",
    "        \"wins\" : 5,\n",
    "        \"losses\" : 2,\n",
    "        \"score\" : 3,\n",
    "        \"status\" : \"winning\",\n",
    "        \"players\": [\n",
    "            {\"id\": 1, \"name\" : \"sam\",  \"shots\" : 3, \"goals\" : 1, \"pct\" : 0.33 },\n",
    "            {\"id\": 2, \"name\" : \"sarah\",  \"shots\" : 0, \"goals\" : 0, \"pct\" : 0.00 },\n",
    "            {\"id\": 3, \"name\" : \"steve\",  \"shots\" : 1, \"goals\" : 1, \"pct\" : 1.00 },\n",
    "            ...\n",
    "        ]\n",
    "    },\n",
    "    \"away\": { ... }\n",
    "}\n",
    "\n",
    "NOTES:\n",
    "\n",
    "* \"status\" should be \"winning\", \"losing\" or \"tied\" based on the current home.score and away.score\n",
    "* the \"_id\" should be the latest event ID from the game stream, at the time the box score was written. \n",
    "* the \"timestamp\" should be the timestamp from the game stream.\n",
    "* Every player on the roster (in the players table) should appear in the box score.\n",
    "* The stats in the box score should be the current stats for the player in game only, and not include the stats in the players table and add up the shot and goal for every player at that point in the game stream.\n",
    "* Calculate the pct field\n",
    "* game is over when the clock hits 00:00.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9610f93",
   "metadata": {},
   "source": [
    "Transform the data into the box score document structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "826d610f-d602-41f6-9238-7f0525782082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "\n",
    "team_stats = final_result.groupBy(\"team_id\").agg(\n",
    "    F.first(\"conference\").alias(\"conference\"),\n",
    "    F.first(\"wins\").alias(\"wins\"),\n",
    "    F.first(\"losses\").alias(\"losses\"),\n",
    "    F.sum(\"goals\").alias(\"score\"),\n",
    "    F.collect_list(\n",
    "        F.struct(\n",
    "            \"jersey_number\", \n",
    "            \"player_name\", \n",
    "            \"shots\", \n",
    "            \"goals\",\n",
    "            F.when(\n",
    "                F.col(\"shots\") > 0, F.col(\"goals\") / F.col(\"shots\")\n",
    "            ).otherwise(F.lit(0)).alias(\"pct\")\n",
    "        )\n",
    "    ).alias(\"players\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e5037d-c228-45c2-8713-80833a37b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = team_stats.withColumn(\n",
    "    \"status\",\n",
    "    F.when(\n",
    "        F.col(\"score\") == F.max(\"score\").over(Window.partitionBy()), \"tied\"\n",
    "    ).otherwise(\n",
    "        F.when(\n",
    "            F.col(\"score\") < F.max(\"score\").over(Window.partitionBy()), \"losing\"\n",
    "        ).otherwise(\"winning\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f65de4b-04ae-415e-97b4-d904efee97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering home and away teams\n",
    "home_team = team_stats.filter(team_stats.team_id == 101)\n",
    "away_team = team_stats.filter(team_stats.team_id == 205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb742a46-5549-4cce-a9d3-c82a92cbd4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:==========================================>          (160 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----+------+-----+--------------------+------+\n",
      "|team_id|conference|wins|losses|score|             players|status|\n",
      "+-------+----------+----+------+-----+--------------------+------+\n",
      "|    101|       acc|  11|     2|   14|[{9, sol, 5, 0, 0...|  tied|\n",
      "+-------+----------+----+------+-----+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "home_team.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48cd9e69-2014-444d-ae5d-fcc75a5a30e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:================================================>    (184 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----+------+-----+--------------------+------+\n",
      "|team_id|conference|wins|losses|score|             players|status|\n",
      "+-------+----------+----+------+-----+--------------------+------+\n",
      "|    205|     big10|   9|     4|    9|[{9, julie, 4, 0,...|losing|\n",
      "+-------+----------+----+------+-----+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "away_team.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d86a8936-48ad-4a8d-96f2-48cbe2019e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_eventid = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MAX(event_id) AS latest_eventid\n",
    "    FROM gamestream\n",
    "    WHERE team_id != 0\n",
    "\"\"\").collect()[0]['latest_eventid']\n",
    "\n",
    "latest_eventid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efcfb7cf-5e9b-4ead-8993-4c025ba07b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'59:51'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_timestamp = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MAX(timestamp) AS latest_timestamp\n",
    "    FROM gamestream\n",
    "    WHERE team_id != 0\n",
    "\"\"\").collect()[0]['latest_timestamp']\n",
    "\n",
    "latest_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0c4b2b5-9d99-4ae8-8757-43e84575ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+--------------+----------------+\n",
      "|event_id|timestamp|team_id|jersey_number|shots|goals|team_goals|player_name|    team_name|conference|wins|losses|latest_eventid|latest_timestamp|\n",
      "+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+--------------+----------------+\n",
      "|      70|    00:00|    101|            9|    5|    0|        14|        sol|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|           10|    3|    1|        14|      swede|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|            2|    7|    2|        14|      steve|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|            8|    4|    0|        14|        sly|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|           13|    7|    1|        14|      stone|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|            6|    4|    2|        14|        sam|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|           15|    3|    1|        14|     shelly|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|            1|    8|    6|        14|      sarah|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|            4|    5|    1|        14|      shree|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    101|           17|    2|    0|        14|       sean|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|      70|    00:00|    205|            9|    4|    0|         9|      julie|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|            2|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|           16|    1|    0|         9|      jimmy|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|            3|    1|    0|         9|       jane|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|           15|    2|    2|         9|       jane|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|            5|    2|    1|         9|      jimmy|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|            1|    3|    3|         9|      jimmy|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|           22|    1|    0|         9|      julie|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|           17|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|      70|    00:00|    205|            8|    2|    1|         9|      julie|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latest_df = final_result.withColumn(\"latest_eventid\", lit(latest_eventid))\\\n",
    "                    .withColumn(\"latest_timestamp\", lit(latest_timestamp))\n",
    "\n",
    "latest_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9026323b-bff0-4f4e-b699-9a8b6d372e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_id': 'event_id',\n",
       " 'timestamp': 'timestamp',\n",
       " 'home': {'team_id': 101,\n",
       "  'conference': 'acc',\n",
       "  'wins': 11,\n",
       "  'losses': 2,\n",
       "  'score': 14,\n",
       "  'players': [{'jersey_number': 9,\n",
       "    'player_name': 'sol',\n",
       "    'shots': 5,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 10,\n",
       "    'player_name': 'swede',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 2,\n",
       "    'player_name': 'steve',\n",
       "    'shots': 7,\n",
       "    'goals': 2,\n",
       "    'pct': 0.2857142857142857},\n",
       "   {'jersey_number': 8,\n",
       "    'player_name': 'sly',\n",
       "    'shots': 4,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 13,\n",
       "    'player_name': 'stone',\n",
       "    'shots': 7,\n",
       "    'goals': 1,\n",
       "    'pct': 0.14285714285714285},\n",
       "   {'jersey_number': 6,\n",
       "    'player_name': 'sam',\n",
       "    'shots': 4,\n",
       "    'goals': 2,\n",
       "    'pct': 0.5},\n",
       "   {'jersey_number': 15,\n",
       "    'player_name': 'shelly',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 1,\n",
       "    'player_name': 'sarah',\n",
       "    'shots': 8,\n",
       "    'goals': 6,\n",
       "    'pct': 0.75},\n",
       "   {'jersey_number': 4,\n",
       "    'player_name': 'shree',\n",
       "    'shots': 5,\n",
       "    'goals': 1,\n",
       "    'pct': 0.2},\n",
       "   {'jersey_number': 17,\n",
       "    'player_name': 'sean',\n",
       "    'shots': 2,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0}],\n",
       "  'status': 'tied'},\n",
       " 'away': {'team_id': 205,\n",
       "  'conference': 'big10',\n",
       "  'wins': 9,\n",
       "  'losses': 4,\n",
       "  'score': 9,\n",
       "  'players': [{'jersey_number': 9,\n",
       "    'player_name': 'julie',\n",
       "    'shots': 4,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 2,\n",
       "    'player_name': 'james',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 16,\n",
       "    'player_name': 'jimmy',\n",
       "    'shots': 1,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 3,\n",
       "    'player_name': 'jane',\n",
       "    'shots': 1,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 15,\n",
       "    'player_name': 'jane',\n",
       "    'shots': 2,\n",
       "    'goals': 2,\n",
       "    'pct': 1.0},\n",
       "   {'jersey_number': 5,\n",
       "    'player_name': 'jimmy',\n",
       "    'shots': 2,\n",
       "    'goals': 1,\n",
       "    'pct': 0.5},\n",
       "   {'jersey_number': 1,\n",
       "    'player_name': 'jimmy',\n",
       "    'shots': 3,\n",
       "    'goals': 3,\n",
       "    'pct': 1.0},\n",
       "   {'jersey_number': 22,\n",
       "    'player_name': 'julie',\n",
       "    'shots': 1,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 17,\n",
       "    'player_name': 'james',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 8,\n",
       "    'player_name': 'julie',\n",
       "    'shots': 2,\n",
       "    'goals': 1,\n",
       "    'pct': 0.5}],\n",
       "  'status': 'losing'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe_to_json(df):\n",
    "    return df.rdd.map(lambda row: row.asDict(recursive=True)).collect()[0]\n",
    "\n",
    "# Convert home and away team stats DataFrames to their corresponding JSON structure\n",
    "home_json = dataframe_to_json(home_team)\n",
    "away_json = dataframe_to_json(away_team)\n",
    "\n",
    "# Construct the box score document\n",
    "box_score_document = {\n",
    "    \"_id\": 'event_id',\n",
    "    \"timestamp\": 'timestamp',\n",
    "    \"home\": home_json,\n",
    "    \"away\": away_json\n",
    "}\n",
    "\n",
    "box_score_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935029f",
   "metadata": {},
   "source": [
    "Write the box score completed to the mongo.sidearm.boxscores collection. \n",
    "The document is keyed by event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff5f9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "box_score_json = json.dumps(box_score_document)\n",
    "\n",
    "box_score_df = spark.read.json(spark.sparkContext.parallelize([box_score_json]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c2db5ac-a46c-4d4c-84d8-0c49c709d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_score_df.write.format(\"mongo\") \\\n",
    "    .option(\"database\", \"sidearm\") \\\n",
    "    .option(\"collection\", \"boxscores\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01394c",
   "metadata": {},
   "source": [
    "PySpark script that will run the entire process of creating the box score document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10472e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_id': 69,\n",
       " 'timestamp': '59:51',\n",
       " 'home': {'team_id': 101,\n",
       "  'conference': 'acc',\n",
       "  'wins': 11,\n",
       "  'losses': 2,\n",
       "  'score': 14,\n",
       "  'players': [{'jersey_number': 9,\n",
       "    'player_name': 'sol',\n",
       "    'shots': 5,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 10,\n",
       "    'player_name': 'swede',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 2,\n",
       "    'player_name': 'steve',\n",
       "    'shots': 7,\n",
       "    'goals': 2,\n",
       "    'pct': 0.2857142857142857},\n",
       "   {'jersey_number': 8,\n",
       "    'player_name': 'sly',\n",
       "    'shots': 4,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 13,\n",
       "    'player_name': 'stone',\n",
       "    'shots': 7,\n",
       "    'goals': 1,\n",
       "    'pct': 0.14285714285714285},\n",
       "   {'jersey_number': 6,\n",
       "    'player_name': 'sam',\n",
       "    'shots': 4,\n",
       "    'goals': 2,\n",
       "    'pct': 0.5},\n",
       "   {'jersey_number': 15,\n",
       "    'player_name': 'shelly',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 1,\n",
       "    'player_name': 'sarah',\n",
       "    'shots': 8,\n",
       "    'goals': 6,\n",
       "    'pct': 0.75},\n",
       "   {'jersey_number': 4,\n",
       "    'player_name': 'shree',\n",
       "    'shots': 5,\n",
       "    'goals': 1,\n",
       "    'pct': 0.2},\n",
       "   {'jersey_number': 17,\n",
       "    'player_name': 'sean',\n",
       "    'shots': 2,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0}],\n",
       "  'status': 'tied'},\n",
       " 'away': {'team_id': 205,\n",
       "  'conference': 'big10',\n",
       "  'wins': 9,\n",
       "  'losses': 4,\n",
       "  'score': 9,\n",
       "  'players': [{'jersey_number': 9,\n",
       "    'player_name': 'julie',\n",
       "    'shots': 4,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 2,\n",
       "    'player_name': 'james',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 16,\n",
       "    'player_name': 'jimmy',\n",
       "    'shots': 1,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 3,\n",
       "    'player_name': 'jane',\n",
       "    'shots': 1,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 15,\n",
       "    'player_name': 'jane',\n",
       "    'shots': 2,\n",
       "    'goals': 2,\n",
       "    'pct': 1.0},\n",
       "   {'jersey_number': 5,\n",
       "    'player_name': 'jimmy',\n",
       "    'shots': 2,\n",
       "    'goals': 1,\n",
       "    'pct': 0.5},\n",
       "   {'jersey_number': 1,\n",
       "    'player_name': 'jimmy',\n",
       "    'shots': 3,\n",
       "    'goals': 3,\n",
       "    'pct': 1.0},\n",
       "   {'jersey_number': 22,\n",
       "    'player_name': 'julie',\n",
       "    'shots': 1,\n",
       "    'goals': 0,\n",
       "    'pct': 0.0},\n",
       "   {'jersey_number': 17,\n",
       "    'player_name': 'james',\n",
       "    'shots': 3,\n",
       "    'goals': 1,\n",
       "    'pct': 0.3333333333333333},\n",
       "   {'jersey_number': 8,\n",
       "    'player_name': 'julie',\n",
       "    'shots': 2,\n",
       "    'goals': 1,\n",
       "    'pct': 0.5}],\n",
       "  'status': 'losing'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        team_id,\n",
    "        jersey_number,\n",
    "        COUNT(*) AS shots,\n",
    "        SUM(shots) AS goals,\n",
    "        teamgoals\n",
    "    FROM \n",
    "        (SELECT \n",
    "            team_id, \n",
    "            jersey_number, \n",
    "            shots, \n",
    "            SUM(shots) OVER (PARTITION BY team_id) as teamgoals\n",
    "         FROM \n",
    "            gamestream\n",
    "         WHERE team_id > 0\n",
    "        ) \n",
    "    GROUP BY \n",
    "        team_id, \n",
    "        jersey_number, \n",
    "        teamgoals\n",
    "    ORDER BY \n",
    "        team_id, \n",
    "        jersey_number\n",
    "\"\"\")\n",
    "\n",
    "# result.show()\n",
    "\n",
    "latest_eventid = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MAX(event_id) AS latest_eventid\n",
    "    FROM gamestream\n",
    "    WHERE team_id != 0\n",
    "\"\"\").collect()[0]['latest_eventid']\n",
    "\n",
    "latest_timestamp = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MAX(timestamp) AS latest_timestamp\n",
    "    FROM gamestream\n",
    "    WHERE team_id != 0\n",
    "\"\"\").collect()[0]['latest_timestamp']\n",
    "\n",
    "latest_df = final_result.withColumn(\"latest_eventid\", lit(latest_eventid))\\\n",
    "                    .withColumn(\"latest_timestamp\", lit(latest_timestamp))\n",
    "\n",
    "players_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "teams_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"teams\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "latest_df.createOrReplaceTempView(\"latest_result\")\n",
    "\n",
    "players_df.createOrReplaceTempView(\"players\")\n",
    "\n",
    "teams_df.createOrReplaceTempView(\"teams\")\n",
    "\n",
    "final_result = spark.sql(\"\"\"\n",
    "SELECT s.*, p.name as player_name, t.name as team_name, t.conference, t.wins, t.losses\n",
    "FROM  score_at_any_point_ingame s\n",
    "LEFT JOIN players p ON s.team_id = p.teamid AND s.jersey_number = p.number\n",
    "LEFT JOIN teams t ON s.team_id = t.id\n",
    "\"\"\")\n",
    "\n",
    "team_stats = final_result.groupBy(\"team_id\").agg(\n",
    "    F.first(\"conference\").alias(\"conference\"),\n",
    "    F.first(\"wins\").alias(\"wins\"),\n",
    "    F.first(\"losses\").alias(\"losses\"),\n",
    "    F.sum(\"goals\").alias(\"score\"),\n",
    "    F.collect_list(\n",
    "        F.struct(\n",
    "            \"jersey_number\", \n",
    "            \"player_name\", \n",
    "            \"shots\", \n",
    "            \"goals\",\n",
    "            F.when(\n",
    "                F.col(\"shots\") > 0, F.col(\"goals\") / F.col(\"shots\")\n",
    "            ).otherwise(F.lit(0)).alias(\"pct\")\n",
    "        )\n",
    "    ).alias(\"players\")\n",
    ")\n",
    "\n",
    "team_stats = team_stats.withColumn(\n",
    "    \"status\",\n",
    "    F.when(\n",
    "        F.col(\"score\") == F.max(\"score\").over(Window.partitionBy()), \"tied\"\n",
    "    ).otherwise(\n",
    "        F.when(\n",
    "            F.col(\"score\") < F.max(\"score\").over(Window.partitionBy()), \"losing\"\n",
    "        ).otherwise(\"winning\")\n",
    "    )\n",
    ")\n",
    "\n",
    "home_team = team_stats.filter(team_stats.team_id == 101)\n",
    "\n",
    "away_team = team_stats.filter(team_stats.team_id == 205)\n",
    "\n",
    "def dataframe_to_json(df):\n",
    "    return df.rdd.map(lambda row: row.asDict(recursive=True)).collect()[0]\n",
    "\n",
    "home_json = dataframe_to_json(home_team)\n",
    "\n",
    "away_json = dataframe_to_json(away_team)\n",
    "\n",
    "# Construct the box score document\n",
    "box_score_document = {\n",
    "    \"_id\": latest_eventid,\n",
    "    \"timestamp\": latest_timestamp,\n",
    "    \"home\": home_json,\n",
    "    \"away\": away_json\n",
    "}\n",
    "\n",
    "box_score_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae5fc9",
   "metadata": {},
   "source": [
    "  \n",
    "# Updating stats in the database when the game is over\n",
    "\n",
    "After the game is complete, the tables in the mssql sidearmdb database should be updated, based on the final box score. Specifically:\n",
    "\n",
    "* update the win/loss record for each team in the teams table\n",
    "* update the shots and goals for each player in the players table\n",
    "\n",
    "NOTES:\n",
    "\n",
    "We will not update the actual tables. Instead we will create new tables called teams2 and players2 with the updated data. It's anti-big data to perform row-level updates. The proper way to move the updates into the original tables would be to write an MSSQL script to update the tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00838524",
   "metadata": {},
   "source": [
    "When the game is complete, write pyspark code to update the wins and losses for the teams in the teams table. \n",
    "Specifically, load the teams table and update it, then display the updated data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "039708a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tied'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_team_status = box_score_document[\"home\"][\"status\"]\n",
    "home_team_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e986adf1-c089-45b0-aa4e-05fae32f47e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'losing'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away_team_status = box_score_document[\"away\"][\"status\"]\n",
    "away_team_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15a5efba-c8c2-4181-9d6f-6204d415f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the team stats\n",
    "def update_team_stats(teams_df, team_id, status):\n",
    "    return teams_df.withColumn(\n",
    "        'wins', \n",
    "        when((col('id') == team_id) & (lit(status) == 'winning'), col('wins') + 1)\n",
    "        .otherwise(col('wins'))\n",
    "    ).withColumn(\n",
    "        'losses', \n",
    "        when((col('id') == team_id) & (lit(status) == 'losing'), col('losses') + 1)\n",
    "        .otherwise(col('losses'))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25fa9b6a-038f-4024-90f9-14b4d06ca43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------+----+------+\n",
      "| id|         name|conference|wins|losses|\n",
      "+---+-------------+----------+----+------+\n",
      "|101|     syracuse|       acc|  11|     2|\n",
      "|205|johns hopkins|     big10|   9|     5|\n",
      "+---+-------------+----------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_teams = update_team_stats(teams_df, 101, home_team_status)\n",
    "df_teams = update_team_stats(teams_df, 205, away_team_status)\n",
    "\n",
    "df_teams.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ea916",
   "metadata": {},
   "source": [
    "Updating teams final data to a new mssql.sidearmdb.teams2 table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "473e48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_teams.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"teams2\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f55c2",
   "metadata": {},
   "source": [
    "Update the shots and goals for the players in the players table. Specifically, load the players table and update it, then display the updated data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b963d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+-----+------+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+--------------+----------------+\n",
      "| id|  name|number|shots|goals|teamid|event_id|timestamp|team_id|jersey_number|shots|goals|team_goals|player_name|    team_name|conference|wins|losses|latest_eventid|latest_timestamp|\n",
      "+---+------+------+-----+-----+------+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+--------------+----------------+\n",
      "| 10| swede|    10|   90|   50|   101|      70|    00:00|    101|           10|    3|    1|        14|      swede|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|  7|   sol|     9|   52|   20|   101|      70|    00:00|    101|            9|    5|    0|        14|        sol|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "| 20| julie|    22|   83|   19|   205|      70|    00:00|    205|           22|    1|    0|         9|      julie|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|  3| steve|     2|   60|   20|   101|      70|    00:00|    101|            2|    7|    2|        14|      steve|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "| 14|  jane|    15|   82|   46|   205|      70|    00:00|    205|           15|    2|    2|         9|       jane|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|  2| sarah|     1|   85|   34|   101|      70|    00:00|    101|            1|    8|    6|        14|      sarah|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|  9|shelly|    15|   10|    2|   101|      70|    00:00|    101|           15|    3|    1|        14|     shelly|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "| 18|  jane|     3|   91|   40|   205|      70|    00:00|    205|            3|    1|    0|         9|       jane|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "| 12| julie|     9|   10|    0|   205|      70|    00:00|    205|            9|    4|    0|         9|      julie|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "| 15| jimmy|    16|   42|   30|   205|      70|    00:00|    205|           16|    1|    0|         9|      jimmy|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "| 19| jimmy|     5|   78|   22|   205|      70|    00:00|    205|            5|    2|    1|         9|      jimmy|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|  5|  sean|    17|   26|    9|   101|      70|    00:00|    101|           17|    2|    0|        14|       sean|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "| 11| jimmy|     1|  100|   50|   205|      70|    00:00|    205|            1|    3|    3|         9|      jimmy|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|  1|   sam|     6|   56|   23|   101|      70|    00:00|    101|            6|    4|    2|        14|        sam|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|  4| stone|    13|   33|   10|   101|      70|    00:00|    101|           13|    7|    1|        14|      stone|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "| 13| james|     2|   45|   15|   205|      70|    00:00|    205|            2|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "|  6|   sly|     8|   78|   15|   101|      70|    00:00|    101|            8|    4|    0|        14|        sly|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "|  8| shree|     4|   20|    4|   101|      70|    00:00|    101|            4|    5|    1|        14|      shree|     syracuse|       acc|  11|     2|            69|           59:51|\n",
      "| 17| james|    17|   40|   14|   205|      70|    00:00|    205|           17|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "| 16| julie|     8|   67|   32|   205|      70|    00:00|    205|            8|    2|    1|         9|      julie|johns hopkins|     big10|   9|     4|            69|           59:51|\n",
      "+---+------+------+-----+-----+------+--------+---------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df_players_with_new_stats = players_df.alias('players').join(\n",
    "    latest_df.alias('new_stats'),\n",
    "    (players_df['name'] == latest_df['player_name']) & \n",
    "    (players_df['number'] == latest_df['jersey_number']),\n",
    "    'left'\n",
    ")\n",
    "\n",
    "df_players_with_new_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'shots' and 'goals' columns by adding new stats to existing stats\n",
    "# If there are no new stats, keep the existing stats\n",
    "df_players_with_updated_stats = df_players_with_new_stats.select(\n",
    "    'players.id',\n",
    "    'players.name',\n",
    "    'players.number',\n",
    "    (F.col('players.shots') + F.coalesce(F.col('new_stats.shots'), F.lit(0))).alias('shots'),\n",
    "    (F.col('players.goals') + F.coalesce(F.col('new_stats.goals'), F.lit(0))).alias('goals'),\n",
    "    'players.teamid'\n",
    ")\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_players_with_updated_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8708552",
   "metadata": {},
   "source": [
    "Update the Players data to a new mssql.sidearmdb.players2 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fee544-2fc5-4e10-aef5-e5fe4909595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_players_with_updated_stats.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players2\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
